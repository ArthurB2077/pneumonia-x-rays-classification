{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "6bd9f332",
   "metadata": {},
   "source": [
    "# Introduction\n",
    "\n",
    "Before begining to demonstrate all the different methods that we used to implement our model, here a presentation of the differents methods that we use during all the step of the model development."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "9e01fa03",
   "metadata": {},
   "source": [
    "\n",
    "## Dataset builder (scripts/x_ray_dataset_builder.py)\n",
    "\n",
    "This class is designed to create and manage image datasets for building our ML models, specifically those using TensorFlow.\n",
    "This class is initialized with parameters such as the directory path containing the image data, the validation split, the subset of data to use, the color mode of the images, the batch size, and the image size."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8590d23d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from x_ray_data_viz import plot_distribution, plot_mean\n",
    "\n",
    "\n",
    "class Dataset:\n",
    "    def __init__(\n",
    "        self,\n",
    "        dir_path: str,\n",
    "        batch_size=40,\n",
    "        color_mode=\"grayscale\",\n",
    "        image_size=(256, 256),\n",
    "        label_mode=\"categorical\",\n",
    "        subset=None,\n",
    "        validation_split=None,\n",
    "    ):\n",
    "        self.batch_size = batch_size\n",
    "        self.class_names = None\n",
    "        self.color_mode = color_mode\n",
    "        self.dataset = None\n",
    "        self.dir_path = dir_path\n",
    "        self.image_size = image_size\n",
    "        self.label_mode = label_mode\n",
    "        self.normalized_dataset = None\n",
    "        self.raw_dataset = None\n",
    "        self.raw_x_dataset = []\n",
    "        self.subset = subset\n",
    "        self.validation_split = validation_split\n",
    "        self.x_dataset = []\n",
    "        self.y_dataset = []"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "a4a1134c",
   "metadata": {},
   "source": [
    "Upon building the dataset using the build method, the class utilizes the image_dataset_from_directory function from TensorFlow's Keras API to load the images and labels directly from the specified directory. \n",
    "The images are then preprocessed using a caching mechanism to speed up future access, and optionally shuffled if the dataset is used for training. The images are also rescaled to a range between 0 and 1 for normalization purposes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81ce59c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "    def build(self, autotune, is_training=False):\n",
    "        dataset = tf.keras.utils.image_dataset_from_directory(\n",
    "            self.dir_path,\n",
    "            batch_size=self.batch_size,\n",
    "            color_mode=self.color_mode,\n",
    "            image_size=self.image_size,\n",
    "            label_mode=self.label_mode,\n",
    "            labels=\"inferred\",\n",
    "            seed=123,\n",
    "            subset=self.subset,\n",
    "            validation_split=self.validation_split,\n",
    "        )\n",
    "\n",
    "        if is_training:\n",
    "            self.dataset = dataset.cache().shuffle(1024).prefetch(buffer_size=autotune)\n",
    "        else:\n",
    "            self.dataset = dataset.cache().prefetch(buffer_size=autotune)\n",
    "\n",
    "        self.class_names = dataset.class_names\n",
    "        self.raw_dataset = dataset\n",
    "\n",
    "        for x, y in dataset.unbatch().as_numpy_iterator():\n",
    "            self.raw_x_dataset.append(x)\n",
    "\n",
    "        self.raw_x_dataset = np.array(self.raw_x_dataset)\n",
    "\n",
    "        normalization_layer = tf.keras.layers.Rescaling(1.0 / 255)\n",
    "        self.normalized_dataset = self.dataset.map(\n",
    "            lambda x, y: (normalization_layer(x), y)\n",
    "        )\n",
    "\n",
    "        for x, y in self.normalized_dataset.unbatch().as_numpy_iterator():\n",
    "            self.x_dataset.append(x)\n",
    "            self.y_dataset.append(y)\n",
    "\n",
    "        self.x_dataset, self.y_dataset = np.array(self.x_dataset), np.array(\n",
    "            self.y_dataset\n",
    "        )\n",
    "\n",
    "        return self.normalized_dataset"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "f1f195a6",
   "metadata": {},
   "source": [
    "\n",
    "The Dataset class provides several utility methods to interact with the created dataset: getting class names, acquiring the shape of batches, and displaying images from a batch. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "272e4625",
   "metadata": {},
   "outputs": [],
   "source": [
    "    def get_class_names(self):\n",
    "        return self.class_names\n",
    "\n",
    "    def get_x_batch_shape(self):\n",
    "        for image_batch, _ in self.dataset:\n",
    "            return image_batch.shape\n",
    "\n",
    "    def get_y_batch_shape(self):\n",
    "        for _, labels_batch in self.dataset:\n",
    "            return labels_batch.shape\n",
    "        \n",
    "    def display_images_in_batch(self, batch_index: int, dataset_name: str):\n",
    "        images, labels = next(iter(self.dataset.take(batch_index)))\n",
    "\n",
    "        plt.figure(figsize=(20, 10))\n",
    "\n",
    "        for i in range(9):\n",
    "            plt.subplot(3, 3, i + 1)\n",
    "            plt.imshow(images[i].numpy().astype(\"uint8\"), cmap=\"gray\")\n",
    "            plt.title(\n",
    "                f\"{dataset_name} - {self.class_names[np.argmax(labels[i])]} (batch {batch_index})\"\n",
    "            )\n",
    "            plt.axis(\"off\")\n",
    "\n",
    "        plt.show()\n",
    "\n",
    "    def display_batch_number(self, dataset_name: str):\n",
    "        total_images = len(self.x_dataset)\n",
    "        batch_size = self.batch_size\n",
    "\n",
    "        total_batches = total_images // batch_size\n",
    "\n",
    "        if total_images % batch_size != 0:\n",
    "            total_batches += 1\n",
    "\n",
    "        batch_indices = list(range(total_batches))\n",
    "        batch_sizes = [batch_size] * total_batches\n",
    "\n",
    "        if total_images % batch_size != 0:\n",
    "            batch_sizes[-1] = total_images % batch_size\n",
    "\n",
    "        plt.figure(figsize=(20, 10))\n",
    "        plt.style.use(\"seaborn\")\n",
    "        plt.bar(batch_indices, batch_sizes, color=\"#ff6f00\")\n",
    "        plt.xlabel(\"Batchs\")\n",
    "        plt.ylabel(\"Images\")\n",
    "        plt.title(f\"Batchs and images per batch in {dataset_name}\")\n",
    "        plt.show()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "6649c45b",
   "metadata": {},
   "source": [
    "It also offers methods to visualize the number of images in each batch and to display the distribution of labels in the dataset. \n",
    "\n",
    "Moreover, it includes a function to calculate and plot the mean of labels. This class is beneficial for data exploration and preprocessing steps, providing a comprehensive tool for managing image datasets in machine learning applications."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67459b3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "    def display_distribution(self, dataset_name: str):\n",
    "        labels_index = np.argmax(self.y_dataset, axis=1)\n",
    "        labels = []\n",
    "\n",
    "        for index in labels_index:\n",
    "            labels.append(self.class_names[index])\n",
    "\n",
    "        plot_distribution(labels, dataset_name)\n",
    "\n",
    "    def display_mean(self, dataset_name):\n",
    "        labels = np.argmax(self.y_dataset, axis=1)\n",
    "        plot_mean(labels, self.class_names, dataset_name)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "dbcfd73e",
   "metadata": {},
   "source": [
    "## Data vizualisation (scripts/data_viz.py)\n",
    "\n",
    "The provided code contains a set of functions designed for visualizing the results of our ML model.\n",
    "These functions use matplotlib and seaborn, popular libraries for data visualization in Python, as well as sklearn for some of the calculations.\n",
    "\n",
    "The function `plot_distribution` visualizes the frequency of each class in the dataset. It creates a bar chart where the x-axis represents the classes (types of chest X-rays) and the y-axis represents the frequency of each class."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c629a9ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "from sklearn.metrics import auc, confusion_matrix, roc_curve\n",
    "from sklearn.preprocessing import label_binarize\n",
    "\n",
    "\n",
    "COLORS = [\"#56f6ff\", \"#e32440\"]\n",
    "PLOT_WIDTH = 20\n",
    "PLOT_HEIGHT = 10\n",
    "\n",
    "def plot_distribution(labels, dataset_name):\n",
    "    plt.figure(figsize=(PLOT_WIDTH, PLOT_HEIGHT))\n",
    "    sns.set_style(\"whitegrid\")\n",
    "    sns.countplot(x=labels, palette=COLORS)\n",
    "    plt.title(f\"{dataset_name} - Chest x-rays distribution\")\n",
    "    plt.xlabel(\"Chest x-ray\")\n",
    "    plt.ylabel(\"Frequency\")\n",
    "    plt.show()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "015e0464",
   "metadata": {},
   "source": [
    "The `plot_mean` function calculates and visualizes the mean occurrence of each class in the dataset. It creates a bar chart with the x-axis representing the classes and the y-axis representing the mean occurrence (in percentage) of each class."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec7081af",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_mean(labels, class_names, dataset_name):\n",
    "    bar_width = 0.25\n",
    "    unique_labels = np.unique(labels)\n",
    "    mean_train = [np.mean(labels == label) * 100 for label in unique_labels]\n",
    "    index = np.arange(len(unique_labels))\n",
    "\n",
    "    plt.figure(figsize=(PLOT_WIDTH, PLOT_HEIGHT))\n",
    "    plt.style.use(\"seaborn\")\n",
    "    plt.bar(\n",
    "        index,\n",
    "        mean_train,\n",
    "        bar_width,\n",
    "        label=class_names,\n",
    "        tick_label=class_names,\n",
    "        color=COLORS,\n",
    "    )\n",
    "    plt.xlabel(\"X-ray images\")\n",
    "    plt.ylabel(\"Mean occurence (%)\")\n",
    "    plt.title(f\"{dataset_name} - Mean occurence of each x-ray image\")\n",
    "    plt.xticks(index, class_names)\n",
    "    plt.legend()\n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "7030b6a0",
   "metadata": {},
   "source": [
    "The `plot_confusion_matrix` function visualizes a confusion matrix, which is a table layout that allows visualization of the performance of a classification model. The rows of the matrix represent the actual classes and the columns represent the predicted classes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed647549",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_confusion_matrix(labels_true, labels_pred, class_names):\n",
    "    matrix = confusion_matrix(labels_true, labels_pred)\n",
    "\n",
    "    plt.figure(figsize=(PLOT_WIDTH, PLOT_HEIGHT))\n",
    "    sns.set_style(\"whitegrid\")\n",
    "    sns.heatmap(\n",
    "        matrix,\n",
    "        annot=True,\n",
    "        cmap=\"YlGnBu\",\n",
    "        fmt=\"d\",\n",
    "        xticklabels=class_names,\n",
    "        yticklabels=class_names,\n",
    "    )\n",
    "    plt.title(\"Confusion matrix\")\n",
    "    plt.xlabel(\"Predicted results\")\n",
    "    plt.ylabel(\"Actual results\")\n",
    "    plt.show()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "296ae161",
   "metadata": {},
   "source": [
    "\n",
    "This function, `plot_roc_curve`, plots the Receiver Operating Characteristic (ROC) curve for each class in a multi-class classification model. \n",
    "\n",
    "The ROC curve is a graphical plot that illustrates the diagnostic ability of a binary classifier system as its discrimination threshold is varied. \n",
    "\n",
    "The function calculates the ROC curve and the Area Under the Curve (AUC) for each class, as well as for the micro-average over all classes, and then plots these curves."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8418f8d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_roc_curve(y_true, y_pred_probs, class_names, binary=False):\n",
    "    y_true_bin = label_binarize(y_true, classes=class_names)\n",
    "    n_classes = len(class_names)\n",
    "\n",
    "    fpr = dict()\n",
    "    tpr = dict()\n",
    "    roc_auc = dict()\n",
    "\n",
    "    for i in range(n_classes):\n",
    "        if binary:\n",
    "            fpr, tpr, _ = roc_curve(y_true_bin, y_pred_probs)\n",
    "            roc_auc = auc(fpr, tpr)\n",
    "        else:\n",
    "            fpr[i], tpr[i], _ = roc_curve(y_true_bin[:, i], y_pred_probs[:, i])\n",
    "            roc_auc[i] = auc(fpr[i], tpr[i])\n",
    "    if binary:\n",
    "        fpr, tpr, thresholds = roc_curve(y_true, y_pred_probs)\n",
    "        roc_auc = auc(fpr, tpr)\n",
    "    else:\n",
    "        fpr[\"micro\"], tpr[\"micro\"], _ = roc_curve(\n",
    "            y_true_bin.ravel(), y_pred_probs.ravel()\n",
    "        )\n",
    "        roc_auc[\"micro\"] = auc(fpr[\"micro\"], tpr[\"micro\"])\n",
    "\n",
    "    plt.figure(figsize=(PLOT_WIDTH, PLOT_HEIGHT))\n",
    "    sns.set_style(\"whitegrid\")\n",
    "\n",
    "    for i in range(n_classes):\n",
    "        if binary:\n",
    "            plt.plot(fpr, tpr, label=f\"Xray (AUC = {roc_auc:.4f})\")\n",
    "        else:\n",
    "            plt.plot(\n",
    "                fpr[i], tpr[i], label=f\"Xray {class_names[i]} (AUC = {roc_auc[i]:.4f})\"\n",
    "            )\n",
    "\n",
    "    plt.plot([0, 1], [0, 1], \"k--\")\n",
    "    plt.xlim([0.0, 0.2])\n",
    "    plt.ylim([0.0, 1.05])\n",
    "    plt.xlabel(\"False positive rate\")\n",
    "    plt.ylabel(\"True positive rate\")\n",
    "    plt.title(\"Receiver Operating Characteristic curve\")\n",
    "    plt.legend(loc=\"lower right\")\n",
    "    plt.show()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "52d8aea4",
   "metadata": {},
   "source": [
    "The function`plot_history` plots the loss and accuracy train/test value from the history of the model.fit() training method."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc62d19e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_history(history):\n",
    "    plt.figure(figsize=(PLOT_WIDTH, PLOT_HEIGHT))\n",
    "    plt.subplot(1, 2, 1)\n",
    "    plt.plot(history.history[\"loss\"], label=\"Training Loss\")\n",
    "    plt.plot(history.history[\"val_loss\"], label=\"Validation Loss\")\n",
    "    plt.title(\"Training and Validation loss\")\n",
    "    plt.xlabel(\"Epochs\")\n",
    "    plt.ylabel(\"Loss\")\n",
    "    plt.legend()\n",
    "\n",
    "    plt.subplot(1, 2, 2)\n",
    "    plt.plot(history.history[\"binary_accuracy\"], label=\"Training accuracy\")\n",
    "    plt.plot(history.history[\"val_binary_accuracy\"], label=\"Validation accuracy\")\n",
    "    plt.title(\"Training and Validation accuracy\")\n",
    "    plt.xlabel(\"Epochs\")\n",
    "    plt.ylabel(\"Accuracy\")\n",
    "    plt.legend()\n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "ad61d0e3",
   "metadata": {},
   "source": [
    "These functions provide visual insights into the distribution of the data and the performance of the classification model, making them valuable tools for model evaluation and interpretation."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "c1652642",
   "metadata": {},
   "source": [
    "## Model loader (scripts/x_ray_model_loader.py)\n",
    "\n",
    "This class is designed to load, evaluate, and make predictions using a pre-trained deep learning model for chest X-ray image classification.\n",
    "The model and data loading utilize TensorFlow and Keras, popular libraries for deep learning in Python, while the model evaluation uses scikit-learn, a library for machine learning in Python.\n",
    "\n",
    "Upon initialization, the `ModelLoader` takes as input a batch size and image size. It sets up a path to the test dataset and loads a list of images to make predictions on. It then initializes a `Dataset` object to handle the test data, and builds it using TensorFlow's AUTOTUNE for optimal data loading."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba974746",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import math\n",
    "import pathlib\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from sklearn.metrics import classification_report\n",
    "from x_ray_data_viz import plot_confusion_matrix, plot_roc_curve\n",
    "from x_ray_dataset_builder import Dataset\n",
    "\n",
    "\n",
    "class ModelLoader:\n",
    "    def __init__(\n",
    "        self,\n",
    "        btch_size=40,\n",
    "        color=\"grayscale\",\n",
    "        img_size=(256, 256),\n",
    "        label_mode=\"categorical\",\n",
    "    ):\n",
    "        pred_list = os.listdir(\"data/prediction/\")\n",
    "\n",
    "        test_dir = pathlib.Path(\"data/test\")\n",
    "\n",
    "        test_ds = Dataset(\n",
    "            test_dir,\n",
    "            batch_size=btch_size,\n",
    "            color_mode=color,\n",
    "            image_size=img_size,\n",
    "            label_mode=label_mode,\n",
    "        )\n",
    "\n",
    "        AUTOTUNE = tf.data.AUTOTUNE\n",
    "        \n",
    "        test_ds.build(AUTOTUNE)\n",
    "\n",
    "        self.class_names = test_ds.get_class_names()\n",
    "        self.loaded_model = None\n",
    "        self.pred_list = pred_list\n",
    "        self.probability_model = None\n",
    "        self.test_ds = test_ds.normalized_dataset\n",
    "        self.x_test = test_ds.x_dataset\n",
    "        self.y_test = test_ds.y_dataset"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "0ab6acf8",
   "metadata": {},
   "source": [
    "\n",
    "The `load` method of the class is used to load a trained model from a given path. It also sets up a probability model, which is the original model wrapped with a softmax layer. The softmax function is often used in the final layer of a neural network-based classifier to produce probabilities for each class."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d353c024",
   "metadata": {},
   "outputs": [],
   "source": [
    "    def load(self, model_pathname, **kwargs):\n",
    "        print(\"\\n\\033[94mModel loading...\\033[0m\")\n",
    "\n",
    "        self.loaded_model = tf.keras.models.load_model(model_pathname, **kwargs)\n",
    "\n",
    "        self.probability_model = tf.keras.Sequential(\n",
    "            [self.loaded_model, tf.keras.layers.Softmax()]\n",
    "        )\n",
    "\n",
    "        print(\"\\n\\033[92mModel successfully loaded!\\033[0m\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "feeb43e7",
   "metadata": {},
   "source": [
    "The `evaluate` method evaluates the loaded model on the test dataset. It prints the loss, categorical accuracy, precision, recall, and area under the ROC curve (AUC) for the test dataset. It then calculates and displays the confusion matrix and ROC curve for the model's performance on the test data. Finally, it prints a classification report, which includes precision, recall, f1-score, and support for each class."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6f154e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "    def evaluate(self, binary=False):\n",
    "        print(\"\\n\\033[94mEvaluating model...\\033[0m\\n\")\n",
    "\n",
    "        if binary:\n",
    "            (\n",
    "                test_loss,\n",
    "                test_binary_accuracy,\n",
    "                test_precision,\n",
    "                test_recall,\n",
    "            ) = self.loaded_model.evaluate(self.x_test, self.y_test, verbose=2)\n",
    "\n",
    "            print(\"\\n\\033[94mEvaluation loss is: %s\\033[0m\" % (test_loss))\n",
    "            print(\"\\n\\033[94mEvaluation binary accurancy is: %s\\033[0m\" % (test_binary_accuracy))\n",
    "            print(\"\\n\\033[94mEvaluation precision is: %s\\033[0m\" % (test_precision))\n",
    "            print(\"\\n\\033[94mEvaluation recall is: %s\\n\\033[0m\" % (test_recall))\n",
    "        else:\n",
    "            (\n",
    "                test_loss,\n",
    "                categorical_accuracy,\n",
    "                test_precision,\n",
    "                test_recall,\n",
    "            ) = self.loaded_model.evaluate(self.x_test, self.y_test, verbose=2)\n",
    "            print(\"\\n\\033[94mEvaluation loss is: %s\\033[0m\" % (test_loss))\n",
    "            print(\"\\n\\033[94mEvaluation categorical accurancy is: %s\\033[0m\" % (categorical_accuracy))\n",
    "            print(\"\\n\\033[94mEvaluation precision is: %s\\033[0m\" % (test_precision))\n",
    "            print(\"\\n\\033[94mEvaluation recall is: %s\\n\\033[0m\" % (test_recall))\n",
    "\n",
    "        predictions = self.loaded_model.predict(self.x_test)\n",
    "        y_test = []\n",
    "        y_pred = []\n",
    "\n",
    "        if binary:\n",
    "            y_test = self.y_test\n",
    "        else:\n",
    "            y_test = np.argmax(self.y_test, axis=1)\n",
    "\n",
    "        if binary:\n",
    "            y_pred = (predictions > 0.5).astype(int).reshape(-1)  # this line is updated\n",
    "        else:\n",
    "            y_pred = np.argmax(predictions, axis=1)\n",
    "\n",
    "        plot_confusion_matrix(y_test, y_pred, class_names=self.class_names)\n",
    "\n",
    "        if binary:\n",
    "            plot_roc_curve(\n",
    "                self.y_test,\n",
    "                predictions,\n",
    "                class_names=self.class_names,\n",
    "                binary=True\n",
    "            )\n",
    "        else:\n",
    "            plot_roc_curve(\n",
    "                self.y_test,\n",
    "                predictions,\n",
    "                class_names=self.class_names\n",
    "            )\n",
    "\n",
    "        print(\"\\033[94m\\nClassification Report:\\033[0m\")\n",
    "        print(\n",
    "            classification_report(\n",
    "                y_test, y_pred, target_names=self.class_names, zero_division=0\n",
    "            )\n",
    "        )"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "cd7ae858",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "The `predict` method is used to make predictions on a set of images stored in a specific folder. It loads each image, processes it, and feeds it to the model for prediction. The predicted class and its probability are then displayed on the image and all images are shown in a grid format using matplotlib."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1dbb2411",
   "metadata": {},
   "outputs": [],
   "source": [
    "    def predict(self, color=\"grayscale\", img_size=(180, 180), binary=False):\n",
    "        num_cols = 4\n",
    "        num_rows = math.ceil(len(self.pred_list) / num_cols)\n",
    "\n",
    "        plt.figure(figsize=(20, 10))\n",
    "\n",
    "        for i in range(len(self.pred_list)):\n",
    "            img = tf.keras.utils.load_img(\n",
    "                f\"data/prediction/{self.pred_list[i]}\",\n",
    "                color_mode=color,\n",
    "                target_size=img_size,\n",
    "            )\n",
    "            img_array = tf.keras.utils.img_to_array(img)\n",
    "            img_array = tf.expand_dims(img_array, 0)\n",
    "            predictions = self.loaded_model.predict(img_array)\n",
    "\n",
    "            score = []\n",
    "\n",
    "            if binary:\n",
    "                score = predictions[0][0]\n",
    "            else:\n",
    "                score = tf.nn.softmax(predictions[0])\n",
    "\n",
    "            plt.subplot(num_rows, num_cols, i + 1)\n",
    "            plt.axis(\"off\")\n",
    "            plt.imshow(img, cmap=\"gray\")\n",
    "            \n",
    "            if binary:\n",
    "                if score > 0.5:\n",
    "                    plt.title(\"Pneumonia ({:.2f}%)\".format(100 * score))\n",
    "                else:\n",
    "                    plt.title(\"Normal ({:.2f}%)\".format(100 * (1 - score)))\n",
    "            else:\n",
    "                plt.title(\n",
    "                    \"{} ({:.2f}%)\".format(\n",
    "                        self.class_names[np.argmax(score)], 100 * np.max(score)\n",
    "                    )\n",
    "                )\n",
    "\n",
    "        plt.show()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "784c0b21",
   "metadata": {},
   "source": [
    "In summary, this class provides a convenient way to load, evaluate, and use a pre-trained model for chest X-ray image classification \n",
    "but this class is really essential because it allow to vizualize the appropriate metrics to evaluate the model's performances."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
